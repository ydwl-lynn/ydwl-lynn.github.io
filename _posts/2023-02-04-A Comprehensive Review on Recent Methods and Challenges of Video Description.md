---
layout: post
title: 论文阅读 - A Comprehensive Review on Recent Methods and Challenges of Video Description
category: Dense video captioning
tag: 博客
---

- *
{:toc}

## 前言
本文对video description每个阶段的方法，数据集，评价指标，公开竞赛，挑战以及未来的发展方向做了详细报告。涵盖主要内容如下：

- 在每个数据集上提出的最先进方法及其优缺点；
-  基准数据集：开放域数据集和特定域数据集；
- 自动评价指标和人工评价的优缺点。
- 该方向面临的主要挑战：相似帧造成冗余影响视觉特征的质量，包含更多样化内容的数据集的可用性，有效评价指标的可用性。

## 研究背景及意义
### 研究背景
多媒体数据量的急剧增长使得研究快速处理和存储数据的有效技术成为必要。视频是最常用的多媒体数据类型，视频数据的巨大增量引起了研究人员的兴趣，他们提出了一种视频描述任务（Video description），旨在以文本（可以是短文本，也可以是长文本）的形式描述视频中的内容、事件和动作。视频是一个丰富的信息来源，它由多个场景、故事、动作、事件、文本和音频组成。视频描述是一项非常具有挑战性的任务。它不仅涉及检测视觉实体及其动作，还旨在通过建立和预测它们之间的关系来提取一些逻辑或有意义的推断，并将其转化为文本形式。该任务是将深度学习应用于计算机视觉(Computer Vision)与自然语言处理(Natural Language Processing)领域的绝佳范例，通过视频描述弥合视觉与语言之间的差距。

### 应用
在互联网领域，视频描述可以用于视频搜索，视频摘要，问答系统，视频鉴黄，广告二维码识别，无意义直播识别，人物识别，视频首图，视频重点识别，新闻拆条，视频查重，视频特效等。在安防领域，视频描述可以用于暴恐涉政识别，异常事件识别，人车分析等。在机器人领域，视频描述可以用于导航，定位，抓取等。在扶残助残方面，视频描述可以对盲人进行导航，将电影或短视频描述给盲人等。目前没有具体产品直接应用视频描述，但是有趣的是，微软已经将图像描述应用于Office365的PowerPoint中，如图1。

![fig1](/images/2023/4/fig1.jpg){:width="550px"}

视频描述和图像描述都是视觉描述的两大类。唯一的区别是内容的性质，图像具有静态内容，在整个分析过程中保持不变，而视频具有随时间变化的动态内容。视频的动态特性使得视频描述过程具有挑战性。根据为视频生成的描述长度，将其分为两类，即。视频字幕（Video captioning）和密集视频字幕（Dense video captioning）如图2所示。从图2中我们可以看到，视频字幕包括对视频整体视觉事件的简明描述，而密集的视频字幕涉及对视频中每个场景的简要描述。

![fig2](/images/2023/4/fig2.png){:width="550px"}

## 视频结构
视频描述方法的性能完全取决于如何有效地编码视频的视觉特征，这些编码的事件特征应该包含对视频中执行的事件和动作进行分类所需的所有必要特征。因此我们首先需要了解视频结构：

视频可以分为三个层次：场景（scenes） 、镜头（shots）和帧（frames）。基于内容、事件和动作，一个视频可以包含多个场景。一个场景由从多个角度捕捉的多个相互关联的连续镜头组成。场景是连续拍摄的相似帧的集合，而帧代表单个图像。因此，从图3中，我们可以看到视频中有许多相似的帧，在视频描述中，选择信息量最大的帧是非常关键的。这就是为什么**信息帧的选择**是最近的视频描述方法[14]的主要焦点。

![fig3](/images/2023/4/fig3.png){:width="550px"}

## 视频描述方法

### 经典的视频描述方法
经典的视觉描述方法有两种类型，分别是基于检索的视频描述方法和基于模板的视频描述方法。

**1. 基于检索的视频描述方法**：主要是基于检测视频中的主题，对象和动作，或者检索具有类似内容的视频标题。
-  **《Association of motion verbs with vehicle movements extracted from dense optical flow fields》（1994）[35]**
本文提出了一种将运动动词与车辆运动联系起来的方法。该方法通过连接64个运动动词并跟踪现实场景中的物体来生成车辆运动的描述。
- **《The" inverse hollywood problem": From video to scripts and storyboards via causal analysis》（AAAI-1997）[10]**
本文通过为视频中执行的动作生成语义标签，来扩展描述生成过程。他们提出了两种方法：第一种是利用“video gister”从视频中提取动作和关键帧用于故事板。第二种提出了一个框架，结合隐马尔可夫模型将视频分割成动作。他们把这个问题看做是“逆好莱坞问题”。其输入是视频，输出是一个脚本，它包含视频中执行的动作以及这些动作（比如：in，out，add，move）的关键帧。该方法的局限性是Gister只能适用于只由一个人的手臂对任意形状的物体进行操作的视频。

<div class="card">
逆好莱坞问题：对动态视频监控主要的目标任务是实现监控对象的行为进行语义化描述。一般在动态图像语义鸿沟之间用架桥的方式（bridge a semantic gap）来解决“逆好莱坞问题”。动态图像序列的语义理解是智能视觉监控的关键理论和方法，是实现智能交通的重要途径。
</div>
		
**2. 基于模板规则的视频描述方法**：首先检测视频中所有相关的动作、事件和实体，然后使用一个固定的模板来生成合适的描述。 

**3. 经典论文**：
- **《 Generating natural language description of human behavior from video images》（ICPR-2000）[33]**
本文提出了一种理解视频中人类行为并生成自然语言描述的方法。在提出的方法中，为了估计人类运动，他们使用了人类头部的姿势和位置。他们从显示出高相似度的样本图像中估计出人头的姿势。每张样本图像的姿势都是已知的，为了估计头部的位置，他们使用了图像平面上的投影变换。为了将人类行为描述成文本形式，使用《The case for case. (1967)》[20]中提出的用于机器翻译的语法案例。但是该方法的缺点是它只适用于仅有一个演员的视频。如果演员的数量增加或者场景更复杂，它会面临很多挑战。
- **《 Monitoring human behavior from video taken in an office environment》（2001）[5]**
本文提出了一种识别人类动作并生成文本描述的方法。在生成描述的同时，他们还从视频中生成了一组关键帧，可用于许多应用，如基于内容的视频压缩、索引和检索。该方法只关注于房间内进行的动作，如enter, sit/stand, pick up objects, put down objects,  open, close, using a computer, cabinet opening, leave等等。为了识别这些动作，模型使用了关于房间布局的先验知识。模型的组成部分是基于颜色的皮肤检测、多个物体的跟踪、场景变化检测和动作识别。该方法的缺点是当视频中的两个人物距离比较近时，模型会出现混乱，如果人的皮肤区域被遮挡，以及提供的先验知识质量不符合要求，模型的性能就会下降。
- **《 Natural language description of human activities from video images based on concept hierarchy of actions》（2002）[34]**
该方法是对其基本方法《Generating natural language description of human behavior from video images》（2000）[33]的扩展。该方法通过以文本形式识别身体每个部位所执行的动作，并将它们整合到最终的描述中。在人体姿势估计中，使用了头部位置、头部方向和手的位置三种几何信息。该方法中，输入图像与背景图像之间的像素差被用于检测输入帧图像中的人类，基于形状的预定义对象匹配被用于动作识别。在识别出人类的动作后，将其与语义基元联系起来。然后，使用三种类型的整合规则将整个身体动作整合到一个案例框架中。最后使用语义规则和词汇词典生成描述。与以往的工作不同的是，本文方法试图解决整个身体动作的问题，但当一个视频中包含多个人物独立行动时，该模型性能不佳。
- **《CASEE: a hierarchical event representation for the analysis of videos》（AAAI-2004）[25]**
本文针对[34]中存在的缺点提出了案例框架的三个扩展（CASEE）。他们提出了一个层次化的CASE，通过使用**子事件**的案例列表来**解决视频中事件相互依赖又各自独立的问题**。为了正确理解事件发生的时间性，他们记录了基于区间代数的时间逻辑，并纳入了事件之间的偶然关系，因为某些子事件的发生取决与其它事件，某些子事件则是独立发生的。
- **《Natural language descriptions of human behavior from video sequences》（2007）[73] **
本文试图解决使用三种语言（Catalan, English, and Spanish）生成人类行动的自然语言描述的问题。本文所提出的框架包含三个子系统，分别是**视觉子系统（VS）**：检测和跟踪视频中的物体；**概念子系统（CS）**：将从VS获得的结构性知识转换成逻辑知识，以便进一步操作和推理；**自然语言子系统（NS）**：用于生成人类动作的描述。自然语言子系统包含三个步骤：词汇化、话语表征和表面实现。词汇化是将CS生成的谓语转换成语言实体，如人物、事件和对象。话语表征结构（DRSs）通过使用适当的句法形式嵌入语义特征来克服自然语言术语中的模糊性，表面实现用于对每个词进行形态学处理。
- **《Save: A framework for semantic annotation of visual events》（CVPR-2008）[37]**
通过考虑基于内容和人类可读查询的视频检索，本文提出了一种名为视觉时间自动语义注释（SAVE）的方法。该方法由三个阶段组成：图像解析、事件推理和文本生成。与[34]中在文本生成过程中使用案例框架不同，基于语法的类似方法被用于注释视频的场景和事件。在第一阶段，使用自下而上的图像分析来提取场景内容。然后从第一阶段提取的内容被传递到事件推理阶段，在这个阶段，视频事件标记语言（VEML）被用来表示语义信息。最后使用头部驱动的短语结构语法（HPSG）生成描述。与之前的方法不同，本文方法生成的描述提供了更多关于场景中存在的视觉实体和它们之间关系的信息。作者将重点放在城市和海洋环境上，以获得更好的描述。
- **《Human focused video description》（ICCV-2011）[31]**
本文提出了一种对视频中人的动作生成描述的方法。在所提出的方法中，通过人脸识别、情绪和人的行为的帮助下预测视频中人的性别。作者使用了2007年和2008年TRECVid提出的用于视频总结任务的rushes视频。这个数据集包含50个片段，一个镜头的长度大约有5-20秒。 除了TRECVid为每个片段提供的1~7个参考注释描述外，他们还使用了20个带有多个短句的人类主体短文描述作为手部注释。 他们采用了一种基于模板的方法来生成描述。 图5显示了用于句子生成的谓语样本。 由于所提出的方法生成的描述与人所做的动作有关，所以它不能在没有人的情况下生成描述，而且这种方法也只能识别预先定义的动作。
- **《Automated textual descriptions for a wide range of video events with 48 human actions》（2012）[26]**
截止到2012年以前，大多数方法都集中在视频单个人所做的动作上。但是，视频中一个事件可能包括由单个或多个人执行的多个动作。为了解决这个问题，[26]提出了一种考虑视频中各种事件的方法。该方法可以解决48种不同类型的动作。该方法包含5个阶段，即视觉处理、融合引擎、事件描述、动作分类器和描述生成器。本文方法采用了两种类型的动作分类器，即鉴别性的特征袋分类器和基于规则的生成分类器。其中基于规则的系统由73条规则组成，用于48种动作。在DARPA数据集（每个视频对应10句描述）上进行实验。该方法的优点是在视频中执行的动作不受限制。局限性在于主体和物体被分为四类（person, car, bike, and other），但主体和物体的分类精度较低。
- **《Video in sentences out》（2012）[8]**
本文提出了一种为短视频生成描述的方法，他们试图解决早期方法的不足之处，如为涉及多人互动的视频生成描述。该方法包括三个步骤，即目标检测、物体跟踪和动态编程。目标检测步骤包括检测每一帧中的目标对象。为了避免过度检测，每帧检测的对象数量被限制在12个。动态编程有助于选择最佳的检测目标集合。为了生成视频描述，本文采用隐马尔可夫模型（HMM）和一套语法规则，最后通过将这些生成的描述标签装入预定义的模板来生成视频的描述。本文方法的缺点是，模型是在高度受限领域的视频（即有限的对象和动作类别）上训练出来的。

**4. 总结**

经典的视频描述方法是通过检测视频中的视觉实体（如物体、动作、场景），并将其放入固定的预定义模板中而产生的。基于规则的系统被用来创建这些模板，它们在受限的环境中是有效的（即短小的片段，或具有有限数量的动作和物体的视频）。基本上，所有经典的视频描述方法背后的主要直觉都是源于着检测视频中的主语、宾语和动词（SVO），并将它们填入一个预先定义的模板中，模板中包括考虑所有的语法规则。大多数传统的视频描述方法可以被认为是一个两阶段的过程，包括**视觉属性的识别**（如对象，对象之间的互动）和**自然语言描述的生成**。
**经典的视频描述方法的缺点**：（1）经典方法在本质上是复杂的；（2）它们要么专注于视频中的一个人，要么只描述交通中车辆的运动；（3）只处理有限的动作（预定义的）；（4）不能产生流畅和连贯的长篇描述。表1报告了所有讨论过的经典视频描述方法的摘要，包括它们的领域和所提出的方法/发现。

![tab1](/images/2023/4/tab1.png){:width="550px"}

### 基于统计方法的方法

### 基于深度学习的方法








